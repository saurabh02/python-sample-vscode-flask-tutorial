# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

# Pipeline-level variables
variables:
  package: hello_app
  distDirectory: dist
  testsDirectory: tests
  artifactFeed: artifact
  registryName: azsamples.azurecr.io
  imageName: hello_app

trigger:
- master
- releases/*
- develop

stages:

- stage: Build

  jobs:

  - job: BuildJob

    pool:
      vmImage: ubuntu-latest

    steps:

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'
        disableDownloadFromRegistry: true # boolean. Disable downloading releases from the GitHub registry. Default: false.
        #allowUnstable: false # boolean. Optional. Use when disableDownloadFromRegistry = false. Allow downloading unstable releases. Default: false.
        #githubToken: # string. Optional. Use when disableDownloadFromRegistry = false. GitHub token for GitHub Actions python registry. 
        addToPath: true # boolean. Required. Add to PATH. Default: true.
      # Advanced
        architecture: 'x64' # 'x86' | 'x64'. Required. Architecture. Default: x64.
      displayName: 'Use Python 3.x'

    # Install some tools needed for build
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      displayName: 'Install dependencies'

    # Lint via pylint. We need to find all .py files and run pylint to avoid errors
    - bash: find . -type f -name "*.py" | xargs pylint
      displayName: "Linting"

    # Run tests
    - bash: pytest --cov=.
      displayName: 'Run tests'
      workingDirectory: $(testsDirectory)

    # Our built source dist & wheel will land in dist
    - bash: python setup.py sdist bdist_wheel
      displayName: Build package

    # Upload everything in dist (including subfolders) to the build artifacts for later use or debugging
    - task: PublishPipelineArtifact@0
      displayName: Create artifacts
      inputs:
        artifactName: $(package)
        targetPath: dist

- stage: Publish

  # We want to wait for all Build Jobs to complete before running the Publish Job
  dependsOn: Build

  # Only publish when the previous Jobs are successful and we're building the master branch
  # condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))

  # Variables specific to the Publish stage
  variables:
    artifactName: $(package)

  jobs:

  - job: PublishPipelineArtifactsJob

    pool:
      vmImage: ubuntu-latest

    steps:

    # Explicitly disable source checkout to keep a pristine environment for publishing
    - checkout: none

    # Set the version of Python to use for publishing (which may or may not match the version the package was built with or tested against)
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'
        disableDownloadFromRegistry: true # boolean. Disable downloading releases from the GitHub registry. Default: false.
        #allowUnstable: false # boolean. Optional. Use when disableDownloadFromRegistry = false. Allow downloading unstable releases. Default: false.
        #githubToken: # string. Optional. Use when disableDownloadFromRegistry = false. GitHub token for GitHub Actions python registry. 
        addToPath: true # boolean. Required. Add to PATH. Default: true.
      # Advanced
        architecture: 'x64' # 'x86' | 'x64'. Required. Architecture. Default: x64.
      displayName: 'Use Python 3.x'

    # Install tools needed for publishing
    - bash: python -m pip install twine
      displayName: Install twine
    
    # Download from build artifacts
    - download: current
      artifact: $(artifactName)

    # Authenticate to Azure Artifacts
    # This sets the PYPIRC_PATH environment variable, which contains credentials for the feed
    - task: TwineAuthenticate@0
      displayName: Configure twine authentication
      inputs:
        artifactFeeds: $(artifactFeed)

    # Upload everything in the dist folder to the private Artifacts feed 
    - bash: twine upload -r $(artifactFeed) --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/$(artifactName)/*
      displayName: Publish artifacts

  # If all Build steps for all Python versions have succeeded,
  # we will download one of the already-validated build assets and package it into a container image
  - job: PublishDockerJob

    dependsOn: PublishPipelineArtifactsJob

    pool:
      vmImage: ubuntu-latest

    steps:

    # Download from build artifacts using the long-form task to control the download path
    # We want the pre-validated package to land at $(Build.SourcesDirectory)/src/simple_server/dist to be available for Docker
    - task: DownloadPipelineArtifact@2
      displayName: Download application
      inputs:
        artifact: $(artifactName)
        path: $(Build.SourcesDirectory)/dist

    # Authenticate to Azure Artifacts
    # This makes the PIP_EXTRA_INDEX_URL Azure DevOps variable / environment var available in future steps
    - task: PipAuthenticate@0
      displayName: Authenticate with artifact feed
      inputs:
        artifactFeeds: $(artifactFeed)

    # Build a container image, passing in the PIP_EXTRA_INDEX_URL from the PipAuthenticate task
    - bash: |
        docker build \
          --build-arg 'PIP_EXTRA_INDEX_URL=$(PIP_EXTRA_INDEX_URL)' \
          -t $(registryName)/$(imageName):$(Build.BuildNumber) \
          .
      displayName: Build container image

    # Only tag `latest` when the previous Steps are successful and we're building the master branch
    - bash: docker tag $(registryName)/$(imageName):$(Build.BuildNumber) $(registryName)/$(imageName):latest
      displayName: Tag `latest` image
      # condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))
